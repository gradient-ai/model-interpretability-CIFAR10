{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Setup and imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Saliency\n",
    "from captum.attr import DeepLift\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as v"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing your Data for Training with DataLoaders"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "class Net(nn.Module): ## create layers as class attributes\n",
    "    def __init__(self): ## Parameters initialization with __init__() function\n",
    "        super(Net, self).__init__() ## call the parent constuctor\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) ## Appy our first set of conv layers\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) ## Apply our first set of max pooling layers\n",
    "        self.pool2 = nn.MaxPool2d(2, 2) ## Apply our second set of maxpooling layers\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) ## second set of conv layers\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) ##first set of fully conneted layers\n",
    "        self.fc2 = nn.Linear(120, 84) ## second set of fullly conneted layers\n",
    "        self.fc3 = nn.Linear(84, 10) ## third set of fully connected layer\n",
    "        self.relu1 = nn.ReLU() ## Apply RELU activation function\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x): ## specify how the model handles the data. \n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "## Model initialization\n",
    "net = Net()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Loss Function and Optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "USE_PRETRAINED_MODEL = True\n",
    "## If using the pretrained model, load it through the function load_state_dict\n",
    "if USE_PRETRAINED_MODEL:\n",
    "    print(\"Using existing trained model\")\n",
    "    net.load_state_dict(torch.load('models/cifar_torchvision.pt'))\n",
    "else:\n",
    "    for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0 ## Resetting running_loss to zero \n",
    "        for i, data in enumerate(trainloader, 0): ## restarts the trainloader iterator on each epoch.\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            # If you don't reset the gradients to zero before each ##backpropagation run, you'll end up with an accumulation of them. \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "           \n",
    "            outputs = net(inputs) ## Carry out the forward pass. \n",
    "            loss = criterion(outputs, labels)## loss computation\n",
    "            loss.backward() ## Carry out backpropagation, and estimate ##gradients. \n",
    "            optimizer.step() ## Make adjustments to the parameters according ##to the gradients. \n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item() ## Build up the batch loss so that we ##can get an average across the epoch. \n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    torch.save(net.state_dict(), 'models/cifar_torchvision.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make a grid of images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Define imwshow function\n",
    "def imshow(img, transpose = True):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy() ## convert image to numpy\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) ## The supplied matrix, npimg, ##has to be transposed into numpy with the values of x,y, and z positioned at ##the indexes 1,2,0 respectively. \n",
    "    plt.show()\n",
    "## iterate through the dataset. Each iteration returns a batch of images and ##labels\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images)) ## Display images with ##torchvision.utils.make_grid() function\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4))) ## Display labels for ground truth\n",
    "\n",
    "outputs = net(images) ## outcome prediction for each batch\n",
    "_, predicted = torch.max(outputs, 1) ## Find the class index that has the ##highest probability and pick that one. \n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] ## Display labels for predicted classes\n",
    "                              for j in range(4)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ind = 3\n",
    "input = images[ind].unsqueeze(0) ## adds an additional dimension to the tensor.\n",
    "input.requires_grad = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Set the model in evaluation mode\n",
    "net.eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set feature attribution function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def attribute_image_f(algorithm, input, **kwargs):\n",
    "    net.zero_grad()\n",
    "    tensor_attributions = algorithm.attribute(input,\n",
    "                                              target=labels[ind],\n",
    "                                              **kwargs\n",
    "                                             )\n",
    "    \n",
    "    return tensor_attributions\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saliency maps"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "saliency = Saliency(net)\n",
    "grads = saliency.attribute(input, target=labels[ind].item())\n",
    "grads = np.transpose(grads.squeeze().cpu().detach().numpy(), (1, 2, 0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Integrated gradients"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ig = IntegratedGradients(net)\n",
    "attrig, delta = attribute_image_f(ig, input, baselines=input * 0, return_convergence_delta=True)\n",
    "attrig = np.transpose(attrig.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "print('Approximation delta: ', abs(delta))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ig = IntegratedGradients(net)\n",
    "nt = NoiseTunnel(ig)\n",
    "attrig_nt = attribute_image_f(nt, input, baselines=input * 0, nt_type='smoothgrad_sq',\n",
    "                                      nt_samples=100, stdevs=0.2)\n",
    "attrig_nt = np.transpose(attrig_nt.squeeze(0).cpu().detach().numpy(), (1, 2, 0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deeplift"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dl = DeepLift(net)\n",
    "attrdl = attribute_image_f(dl, input, baselines=input * 0)\n",
    "attrdl = np.transpose(attrdl.squeeze(0).cpu().detach().numpy(), (1, 2, 0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization of attributes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Original Image')\n",
    "print('Predicted:', classes[predicted[ind]], \n",
    "      ' Probability:', torch.max(F.softmax(outputs, 1)).item())\n",
    "\n",
    "original_image = np.transpose((images[ind].cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\n",
    "\n",
    "_ = v.visualize_image_attr(None, original_image, \n",
    "                      method=\"original_image\", title=\"Original Image\")\n",
    "\n",
    "_ = v.visualize_image_attr(grads, original_image, method=\"blended_heat_map\", sign=\"absolute_value\",\n",
    "                          show_colorbar=True, title=\"Overlayed Gradient Magnitudes\")\n",
    "\n",
    "_ = v.visualize_image_attr(attrig, original_image, method=\"blended_heat_map\",sign=\"all\",\n",
    "                          show_colorbar=True, title=\"Overlayed Integrated Gradients\")\n",
    "\n",
    "_ = v.visualize_image_attr(attrig_nt, original_image, method=\"blended_heat_map\", sign=\"absolute_value\", \n",
    "                             outlier_perc=10, show_colorbar=True, \n",
    "                             title=\"Overlayed Integrated Gradients \\n with SmoothGrad Squared\")\n",
    "\n",
    "_ = v.visualize_image_attr(attrdl, original_image, method=\"blended_heat_map\",sign=\"all\",show_colorbar=True, \n",
    "                          title=\"Overlayed DeepLift\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}